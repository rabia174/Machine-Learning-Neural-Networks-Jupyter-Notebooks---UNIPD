{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kuzushiji Classification with Support Vector Machines\n",
    "\n",
    "In this notebook we are going to explore the use of Support Vector Machines (SVM) for image classification. We will use a variant of the famous MNIST dataset (the original is a dataset of handwritten digits). The version we are going to use is called Kuzushiji-MNIST or K-MNIST for short (https://github.com/rois-codh/kmnist) and is a dataset of traditional japanese handwritten kana.\n",
    "\n",
    "\n",
    "\n",
    "The dataset labels are the following:\n",
    "\n",
    "| Label | Hiragana Character | Romanji (Pronunciation) |\n",
    "| :-: | :-: | :-: |\n",
    "|   0   | お | o |\n",
    "| 1 | き | ki |\n",
    "| 2 | す | su |\n",
    "| 3 | つ | tsu |\n",
    "| 4 | な | na |\n",
    "| 5 | は | ha |\n",
    "| 6 | ま | ma |\n",
    "| 7 | や | ya |\n",
    "| 8 | れ | re |\n",
    "| 9 | を | wo |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Insert your surname, name and ID number\n",
    "\n",
    "Student surname: Yapıcıoğlu\n",
    "\n",
    "Student name: Fatıma Rabia\n",
    "    \n",
    "ID: 2049536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the required packages\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to load Kuzushiji-MNIST dataset\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "    labels_path = os.path.join(path, 'K%s-labels-idx1-ubyte.gz' % kind)\n",
    "    images_path = os.path.join(path, 'K%s-images-idx3-ubyte.gz' % kind)\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,offset=8)\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,offset=16).reshape(len(labels), 784)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix your ID (\"numero di matricola\") and the seed for random generator (as usual you can try different seeds)\n",
    "ID = 2049536\n",
    "np.random.seed(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n"
     ]
    }
   ],
   "source": [
    "#load the K-MNIST dataset from the 'data' folder and let's normalize the features so that each value is in [0,1] \n",
    "\n",
    "X, y = load_mnist('data', kind='train')\n",
    "# rescale the data\n",
    "X, y = X / 255., y # original pixel values are between 0 and 255\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split into training and test. Make sure that each label is present at least 10 times\n",
    "in training. If it is not, then keep adding permutations to the initial data until this \n",
    "happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in training dataset:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Frequencies in training dataset:  [70 50 54 56 59 61 73 71 57 49]\n"
     ]
    }
   ],
   "source": [
    "# Random permute the data and split into training and test taking the first 600\n",
    "# data samples as training and 4000 samples as test\n",
    "permutation = np.random.permutation(X.shape[0])\n",
    "\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 600\n",
    "m_test = 4000\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:m_training+m_test:]\n",
    "y_train, y_test = y[:m_training], y[m_training:m_training+m_test:]\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for plotting a image and printing the corresponding label\n",
    "def plot_input(X_matrix, labels, index):\n",
    "    print(\"INPUT:\")\n",
    "    plt.imshow(\n",
    "        X_matrix[index].reshape(28,28),\n",
    "        cmap          = plt.cm.gray_r,\n",
    "        interpolation = \"nearest\"\n",
    "    )\n",
    "    plt.show()\n",
    "    print(\"LABEL: %i\"%labels[index])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 1\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 8\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 2\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 8\n"
     ]
    }
   ],
   "source": [
    "#let's try the plotting function\n",
    "plot_input(X_train,y_train,5)\n",
    "plot_input(X_test,y_test,50)\n",
    "plot_input(X_test,y_test,500)\n",
    "plot_input(X_test,y_test,700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 1\n",
    "Use a SVM classifier with cross validation to pick a model. Use a 4-fold cross-validation. Let's start with a Linear kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import SVC\n",
    "from sklearn.svm import SVC\n",
    "#import for Cross-Validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters for linear SVM\n",
    "parameters = {'C': [0.01, 0.1, 1, 10]}\n",
    "\n",
    "#train linear SVM\n",
    "svc = SVC(kernel='linear')\n",
    "clf = GridSearchCV(svc, parameters,cv=5)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LINEAR KERNEL\n",
      "Best parameters set found:\n",
      "{'C': 0.01}\n",
      "Best estimator found:\n",
      "SVC(C=0.01, kernel='linear')\n",
      "Score with best parameters:\n",
      "0.7166666666666666\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038201</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.008215</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.015811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039197</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.008282</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.031002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039657</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.008770</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.030459</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040218</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.007588</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.030459</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.038201      0.002653         0.008215        0.000623    0.01   \n",
       "1       0.039197      0.002845         0.008282        0.000815     0.1   \n",
       "2       0.039657      0.003461         0.008770        0.001278       1   \n",
       "3       0.040218      0.002972         0.007588        0.000751      10   \n",
       "\n",
       "        params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'C': 0.01}              0.725                0.7           0.741667   \n",
       "1   {'C': 0.1}              0.725                0.7           0.733333   \n",
       "2     {'C': 1}              0.725                0.7           0.725000   \n",
       "3    {'C': 10}              0.725                0.7           0.725000   \n",
       "\n",
       "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.700000           0.716667         0.716667        0.015811   \n",
       "1           0.675000           0.650000         0.696667        0.031002   \n",
       "2           0.666667           0.650000         0.693333        0.030459   \n",
       "3           0.666667           0.650000         0.693333        0.030459   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                2  \n",
       "2                3  \n",
       "3                3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADD YOUR CODE\n",
    "print ('RESULTS FOR LINEAR KERNEL')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "# ADD YOUR CODE\n",
    "print(clf.best_params_)\n",
    "\n",
    "print(\"Best estimator found:\")\n",
    "# ADD YOUR CODE\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "\n",
    "# ADD YOUR CODE\n",
    "clf = GridSearchCV(svc, parameters,refit=True,cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_score_)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(\"All scores on the grid:\")\n",
    "\n",
    "# ADD YOUR CODE\n",
    "all_scores = pd.DataFrame(clf.cv_results_)\n",
    "\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 2\n",
    "Pick a model for the Polynomial kernel with degree=2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR POLY DEGREE=2 KERNEL\n",
      "Best parameters set found:\n",
      "{'C': 0.01, 'gamma': 1}\n",
      "Best estimator found:\n",
      "SVC(C=0.01, degree=2, gamma=1, kernel='poly')\n",
      "Score with best parameters:\n",
      "0.7416666666666666\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.056279</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.009220</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.01}</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.121667</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046655</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.009411</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.1}</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.011304</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.051612</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.009280</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.01, 'gamma': 1}</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.015811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058121</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.010436</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.01}</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.053593</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048782</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>0.008505</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1}</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.009718</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.046493</td>\n",
       "      <td>0.005530</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 1}</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.015811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.046411</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.011304</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.049189</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.008058</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.015811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.050697</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.008096</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1, 'gamma': 1}</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.015811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.056279      0.004684         0.009220        0.000667    0.01   \n",
       "1       0.046655      0.002931         0.009411        0.000570    0.01   \n",
       "2       0.051612      0.004739         0.009280        0.000772    0.01   \n",
       "3       0.058121      0.004134         0.010436        0.001716     0.1   \n",
       "4       0.048782      0.004072         0.008505        0.001090     0.1   \n",
       "5       0.046493      0.005530         0.008261        0.000807     0.1   \n",
       "6       0.046411      0.005742         0.008888        0.000589       1   \n",
       "7       0.049189      0.001838         0.008058        0.000868       1   \n",
       "8       0.050697      0.003113         0.008096        0.000803       1   \n",
       "\n",
       "  param_gamma                      params  split0_test_score  \\\n",
       "0        0.01  {'C': 0.01, 'gamma': 0.01}           0.125000   \n",
       "1         0.1   {'C': 0.01, 'gamma': 0.1}           0.741667   \n",
       "2           1     {'C': 0.01, 'gamma': 1}           0.733333   \n",
       "3        0.01   {'C': 0.1, 'gamma': 0.01}           0.491667   \n",
       "4         0.1    {'C': 0.1, 'gamma': 0.1}           0.725000   \n",
       "5           1      {'C': 0.1, 'gamma': 1}           0.733333   \n",
       "6        0.01     {'C': 1, 'gamma': 0.01}           0.741667   \n",
       "7         0.1      {'C': 1, 'gamma': 0.1}           0.733333   \n",
       "8           1        {'C': 1, 'gamma': 1}           0.733333   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.125000           0.116667           0.116667           0.125000   \n",
       "1           0.716667           0.741667           0.733333           0.716667   \n",
       "2           0.716667           0.758333           0.741667           0.758333   \n",
       "3           0.383333           0.533333           0.416667           0.475000   \n",
       "4           0.725000           0.750000           0.733333           0.741667   \n",
       "5           0.716667           0.758333           0.741667           0.758333   \n",
       "6           0.716667           0.741667           0.733333           0.716667   \n",
       "7           0.716667           0.758333           0.741667           0.758333   \n",
       "8           0.716667           0.758333           0.741667           0.758333   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.121667        0.004082                9  \n",
       "1         0.730000        0.011304                6  \n",
       "2         0.741667        0.015811                1  \n",
       "3         0.460000        0.053593                8  \n",
       "4         0.735000        0.009718                5  \n",
       "5         0.741667        0.015811                1  \n",
       "6         0.730000        0.011304                6  \n",
       "7         0.741667        0.015811                1  \n",
       "8         0.741667        0.015811                1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters for poly with degree 2 kernel\n",
    "parameters = {'C': [0.01, 0.1, 1],'gamma':[0.01,0.1,1]}\n",
    "\n",
    "#run SVM with poly of degree 2 kernel\n",
    "\n",
    "# ADD YOUR CODE\n",
    "\n",
    "grid = GridSearchCV(SVC(kernel='poly',degree=2),parameters,refit=True)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "print ('RESULTS FOR POLY DEGREE=2 KERNEL')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "# ADD YOUR CODE\n",
    "print(grid.best_params_)\n",
    "\n",
    "print(\"Best estimator found:\")\n",
    "# ADD YOUR CODE\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "# ADD YOUR CODE\n",
    "print(grid.best_score_)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(\"All scores on the grid:\")\n",
    "\n",
    "# ADD YOUR CODE\n",
    "all_scores = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 3\n",
    "\n",
    "Now let's try a higher degree for the polynomial kernel (e.g., 3rd degree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR POLY DEGREE= 3  KERNEL\n",
      "Best parameters set found:\n",
      "{'C': 0.01, 'gamma': 0.1}\n",
      "Best estimator found:\n",
      "SVC(C=0.01, gamma=0.1, kernel='poly')\n",
      "Score with best parameters:\n",
      "0.7066666666666668\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058194</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.009204</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.01}</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.121667</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053965</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>0.008412</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.1}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.031358</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.053765</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>0.008437</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.01, 'gamma': 1}</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.056189</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.010461</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.01}</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.398333</td>\n",
       "      <td>0.039581</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.055442</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>0.008729</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1}</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.055772</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>0.008438</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 1}</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.049097</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.051455</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>0.007971</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.055096</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1, 'gamma': 1}</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.058194      0.002518         0.009204        0.000665    0.01   \n",
       "1       0.053965      0.005032         0.008412        0.000584    0.01   \n",
       "2       0.053765      0.004897         0.008437        0.000844    0.01   \n",
       "3       0.056189      0.001893         0.010461        0.002107     0.1   \n",
       "4       0.055442      0.003718         0.008729        0.000637     0.1   \n",
       "5       0.055772      0.003417         0.008438        0.000739     0.1   \n",
       "6       0.049097      0.004889         0.007975        0.000475       1   \n",
       "7       0.051455      0.004670         0.007971        0.000869       1   \n",
       "8       0.055096      0.004551         0.008139        0.000881       1   \n",
       "\n",
       "  param_gamma                      params  split0_test_score  \\\n",
       "0        0.01  {'C': 0.01, 'gamma': 0.01}           0.125000   \n",
       "1         0.1   {'C': 0.01, 'gamma': 0.1}           0.666667   \n",
       "2           1     {'C': 0.01, 'gamma': 1}           0.708333   \n",
       "3        0.01   {'C': 0.1, 'gamma': 0.01}           0.416667   \n",
       "4         0.1    {'C': 0.1, 'gamma': 0.1}           0.708333   \n",
       "5           1      {'C': 0.1, 'gamma': 1}           0.708333   \n",
       "6        0.01     {'C': 1, 'gamma': 0.01}           0.675000   \n",
       "7         0.1      {'C': 1, 'gamma': 0.1}           0.708333   \n",
       "8           1        {'C': 1, 'gamma': 1}           0.708333   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.125000           0.116667           0.116667           0.125000   \n",
       "1           0.683333           0.758333           0.716667           0.708333   \n",
       "2           0.658333           0.725000           0.683333           0.708333   \n",
       "3           0.358333           0.466667           0.366667           0.383333   \n",
       "4           0.658333           0.725000           0.683333           0.708333   \n",
       "5           0.658333           0.725000           0.683333           0.708333   \n",
       "6           0.675000           0.725000           0.683333           0.708333   \n",
       "7           0.658333           0.725000           0.683333           0.708333   \n",
       "8           0.658333           0.725000           0.683333           0.708333   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.121667        0.004082                9  \n",
       "1         0.706667        0.031358                1  \n",
       "2         0.696667        0.023333                2  \n",
       "3         0.398333        0.039581                8  \n",
       "4         0.696667        0.023333                2  \n",
       "5         0.696667        0.023333                2  \n",
       "6         0.693333        0.020000                7  \n",
       "7         0.696667        0.023333                2  \n",
       "8         0.696667        0.023333                2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters for poly with higher degree kernel\n",
    "parameters = {'C': [0.01, 0.1, 1],'gamma':[0.01,0.1,1]}\n",
    "\n",
    "#run SVM with poly of higher degree kernel\n",
    "degree = 3\n",
    "\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print ('RESULTS FOR POLY DEGREE=', degree, ' KERNEL')\n",
    "\n",
    "grid = GridSearchCV(SVC(kernel='poly',degree=3),parameters,refit=True)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "# ADD YOUR CODE\n",
    "print(grid.best_params_)\n",
    "\n",
    "print(\"Best estimator found:\")\n",
    "# ADD YOUR CODE\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "# ADD YOUR CODE\n",
    "print(grid.best_score_)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(\"All scores on the grid:\")\n",
    "\n",
    "# ADD YOUR CODE\n",
    "all_scores = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 4\n",
    "Pick a model for the Radial Basis Function kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found:\n",
      "{'C': 10, 'gamma': 0.01}\n",
      "Best estimator found:\n",
      "SVC(C=10, gamma=0.01)\n",
      "Score with best parameters:\n",
      "0.7833333333333333\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066775</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.025793</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.001}</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.121667</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064720</td>\n",
       "      <td>0.004288</td>\n",
       "      <td>0.026310</td>\n",
       "      <td>0.006392</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.01}</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.238333</td>\n",
       "      <td>0.020138</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071662</td>\n",
       "      <td>0.009104</td>\n",
       "      <td>0.025657</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1}</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.121667</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.073364</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 1}</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.121667</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.052801</td>\n",
       "      <td>0.004041</td>\n",
       "      <td>0.023981</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.031358</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.063514</td>\n",
       "      <td>0.004337</td>\n",
       "      <td>0.024735</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.074622</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.025376</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.191667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.178333</td>\n",
       "      <td>0.035198</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.069426</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>0.024420</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1, 'gamma': 1}</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.121667</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.043956</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.023031</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.025495</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.065935</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>0.022131</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.013944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.068703</td>\n",
       "      <td>0.004403</td>\n",
       "      <td>0.024630</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.191667</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.203333</td>\n",
       "      <td>0.029627</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.086201</td>\n",
       "      <td>0.005358</td>\n",
       "      <td>0.028078</td>\n",
       "      <td>0.004209</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 10, 'gamma': 1}</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.121667</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.048564</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>0.022325</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.711667</td>\n",
       "      <td>0.035590</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.068120</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.025008</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.013944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.071860</td>\n",
       "      <td>0.004276</td>\n",
       "      <td>0.023124</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1}</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.191667</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.203333</td>\n",
       "      <td>0.029627</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.077900</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.024201</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 100, 'gamma': 1}</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.121667</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.066775      0.001259         0.025793        0.001046     0.1   \n",
       "1        0.064720      0.004288         0.026310        0.006392     0.1   \n",
       "2        0.071662      0.009104         0.025657        0.000820     0.1   \n",
       "3        0.073364      0.003300         0.025600        0.002812     0.1   \n",
       "4        0.052801      0.004041         0.023981        0.002283       1   \n",
       "5        0.063514      0.004337         0.024735        0.001972       1   \n",
       "6        0.074622      0.004256         0.025376        0.001507       1   \n",
       "7        0.069426      0.004312         0.024420        0.003068       1   \n",
       "8        0.043956      0.003567         0.023031        0.000976      10   \n",
       "9        0.065935      0.003981         0.022131        0.001883      10   \n",
       "10       0.068703      0.004403         0.024630        0.002620      10   \n",
       "11       0.086201      0.005358         0.028078        0.004209      10   \n",
       "12       0.048564      0.004709         0.022325        0.000922     100   \n",
       "13       0.068120      0.005478         0.025008        0.000896     100   \n",
       "14       0.071860      0.004276         0.023124        0.003403     100   \n",
       "15       0.077900      0.000406         0.024201        0.002403     100   \n",
       "\n",
       "   param_gamma                      params  split0_test_score  \\\n",
       "0        0.001  {'C': 0.1, 'gamma': 0.001}           0.125000   \n",
       "1         0.01   {'C': 0.1, 'gamma': 0.01}           0.241667   \n",
       "2          0.1    {'C': 0.1, 'gamma': 0.1}           0.125000   \n",
       "3            1      {'C': 0.1, 'gamma': 1}           0.125000   \n",
       "4        0.001    {'C': 1, 'gamma': 0.001}           0.558333   \n",
       "5         0.01     {'C': 1, 'gamma': 0.01}           0.791667   \n",
       "6          0.1      {'C': 1, 'gamma': 0.1}           0.191667   \n",
       "7            1        {'C': 1, 'gamma': 1}           0.125000   \n",
       "8        0.001   {'C': 10, 'gamma': 0.001}           0.775000   \n",
       "9         0.01    {'C': 10, 'gamma': 0.01}           0.808333   \n",
       "10         0.1     {'C': 10, 'gamma': 0.1}           0.208333   \n",
       "11           1       {'C': 10, 'gamma': 1}           0.125000   \n",
       "12       0.001  {'C': 100, 'gamma': 0.001}           0.750000   \n",
       "13        0.01   {'C': 100, 'gamma': 0.01}           0.808333   \n",
       "14         0.1    {'C': 100, 'gamma': 0.1}           0.208333   \n",
       "15           1      {'C': 100, 'gamma': 1}           0.125000   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.125000           0.116667           0.116667   \n",
       "1            0.233333           0.216667           0.275000   \n",
       "2            0.125000           0.116667           0.116667   \n",
       "3            0.125000           0.116667           0.116667   \n",
       "4            0.600000           0.608333           0.550000   \n",
       "5            0.741667           0.783333           0.791667   \n",
       "6            0.200000           0.141667           0.133333   \n",
       "7            0.125000           0.116667           0.116667   \n",
       "8            0.725000           0.766667           0.716667   \n",
       "9            0.775000           0.783333           0.783333   \n",
       "10           0.208333           0.191667           0.158333   \n",
       "11           0.125000           0.116667           0.116667   \n",
       "12           0.716667           0.750000           0.666667   \n",
       "13           0.775000           0.783333           0.783333   \n",
       "14           0.208333           0.191667           0.158333   \n",
       "15           0.125000           0.116667           0.116667   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.125000         0.121667        0.004082               11  \n",
       "1            0.225000         0.238333        0.020138                7  \n",
       "2            0.125000         0.121667        0.004082               11  \n",
       "3            0.125000         0.121667        0.004082               11  \n",
       "4            0.633333         0.590000        0.031358                6  \n",
       "5            0.741667         0.770000        0.023333                3  \n",
       "6            0.225000         0.178333        0.035198               10  \n",
       "7            0.125000         0.121667        0.004082               11  \n",
       "8            0.716667         0.740000        0.025495                4  \n",
       "9            0.766667         0.783333        0.013944                1  \n",
       "10           0.250000         0.203333        0.029627                8  \n",
       "11           0.125000         0.121667        0.004082               11  \n",
       "12           0.675000         0.711667        0.035590                5  \n",
       "13           0.766667         0.783333        0.013944                1  \n",
       "14           0.250000         0.203333        0.029627                8  \n",
       "15           0.125000         0.121667        0.004082               11  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters for rbf SVM\n",
    "parameters = {'C': [0.1, 1, 10, 100],'gamma':[0.001, 0.01, 0.1,1]}\n",
    "\n",
    "#run SVM with rbf kernel\n",
    "grid = GridSearchCV(SVC(kernel='rbf',degree=3),parameters,refit=True)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "# ADD YOUR CODE\n",
    "print(grid.best_params_)\n",
    "\n",
    "print(\"Best estimator found:\")\n",
    "# ADD YOUR CODE\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "# ADD YOUR CODE\n",
    "print(grid.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "print(\"All scores on the grid:\")\n",
    "\n",
    "# ADD YOUR CODE\n",
    "all_scores = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 1\n",
    "What do you observe when using linear, polynomial and RBF kernels on this dataset ?\n",
    "\n",
    "I observed that the model which provides highest score with the best parameters is the one with 'rbf' kernel. Polynomial kernel degree=2 SVM has performed better than the linear one and the polynomial degree=3 one. When we use the polynomial kernel, we need to find optimum degree in order not to overshoot the minumum loss or in order not to overfit to data, which then leads to a model not generalized well. GridSearchCV method applies both cross-validation and different combination of parameters that we provided. C is the regularization parameter. The strength of the regularization is inversely proportional to C. The model which has performed best has tuned C as 10. Gamma is the kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. The best performed model that I observed has tuned the gamma as 0.01. This combination on the paramer grid provides the overall best performance among the ones that I've computed above.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 5\n",
    "Report here the best SVM kernel and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM training error: 0.000000\n",
      "Best SVM test error: 0.190000\n"
     ]
    }
   ],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "best_SVM = SVC( kernel='rbf', degree=3, C=10, gamma=0.01)\n",
    "\n",
    "# ADD YOUR CODE\n",
    "best_SVM.fit(X_train,y_train)\n",
    "\n",
    "training_error = 1 - best_SVM.score(X_train,y_train)\n",
    "test_error = 1 - best_SVM.score(X_test,y_test)\n",
    "# (error is 1 - svm.score)\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 6\n",
    "\n",
    "Analyze how the gamma parameter (inversely proportional to standard deviation of Gaussian Kernel) impact the performances of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.e-05 1.e-04 1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]\n"
     ]
    }
   ],
   "source": [
    "#Test with different values of gamma\n",
    "\n",
    "# Set gamma values\n",
    "gamma_values = np.logspace(-5,2,8)\n",
    "print(gamma_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try the SVM with the previously set values of gamma\n",
    "# use rbf kernel and C=1\n",
    "\n",
    "train_acc_list, test_acc_list = [], []\n",
    "\n",
    "    \n",
    "# ADD YOUR CODE TO TRAIN THE SVM MULTIPLE TIMES WITH THE DIFFERENT VALUES OF GAMMA\n",
    "# PLACE THE TRAIN AND TEST ACCURACY FOR EACH TEST IN THE TRAIN AND TEST ACCURACY LISTS\n",
    "for i in range(len(gamma_values)):\n",
    "    best_SVM = SVC( kernel='rbf', degree=3, C=10, gamma=gamma_values[i])\n",
    "    best_SVM.fit(X_train,y_train)\n",
    "    training_accuracy = best_SVM.score(X_train,y_train)\n",
    "    test_accuracy = best_SVM.score(X_test,y_test)\n",
    "    train_acc_list.append(training_accuracy)\n",
    "    test_acc_list.append(test_accuracy)\n",
    "    \n",
    "# Plot\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "ax[0].plot(gamma_values, train_acc_list)\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_xlabel('gamma')\n",
    "ax[0].set_ylabel('Train accuracy')\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(gamma_values, test_acc_list)\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_xlabel('gamma')\n",
    "ax[1].set_ylabel('Test accuracy')\n",
    "ax[1].grid(True)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 2\n",
    "How do the train and test error change when changing gamma ? Which is the best value of gamma ? \n",
    "Connect your answers to the discussion about the overfitting issue.\n",
    "\n",
    "Until the gamma value reaches 0.01 both the training accuracy and the test accuracy increased. Once it may seem like when gamma increases the training accuracy and the test accuracy seem to be increasing, but this assumption is wrong. Because as it can be seen from the plot after 0.01 test accuracy started to decrese even though the training accuracy is stable and provides %100 accuracy. This means that if the training accuracy provides good accuracy results despite the fact that test accuracy is decreasing, the model will overfit starting from that point. Therefore as an optimal gamma value we can take 0.01 in order not to overfit dataset and generalize better.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data\n",
    "Now let's do the same but using more data points for training.\n",
    "\n",
    "\n",
    "Choose a new number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in training dataset:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Frequencies in training dataset:  [178 223 188 192 202 198 207 207 204 201]\n"
     ]
    }
   ],
   "source": [
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 2000 # TODO number of data points, adjust depending on the capabilities of your PC\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 7\n",
    "\n",
    "Let's try to use SVM with parameters obtained from the best model for $m_{training} =  2000$. Since it may take a long time to run, you can decide to just let it run for some time and stop it if it does not complete. If you decide to do this, report it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM training error: 0.000000\n",
      "Best SVM test error: 0.116897\n"
     ]
    }
   ],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "\n",
    "best_SVM = SVC( kernel='rbf', degree=3, C=10, gamma=0.01)\n",
    "best_SVM.fit(X_train,y_train)\n",
    "training_error = 1 - best_SVM.score(X_train,y_train)\n",
    "test_error = 1 - best_SVM.score(X_test,y_test)\n",
    "\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for comparison, let's also use logistic regression \n",
    "\n",
    "## TO DO 8 Try first without regularization (use a very large large C)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression training error: 0.000000\n",
      "Best logistic regression test error: 0.281086\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# ADD YOUR CODE\n",
    "lr = linear_model.LogisticRegression( random_state=0, C=100000, max_iter=500 ).fit(X_train, y_train)\n",
    "training_error = 1- lr.score(X_train,y_train)\n",
    "test_error = 1 - lr.score(X_test, y_test)\n",
    "\n",
    "print (\"Best logistic regression training error: %f\" % training_error)\n",
    "print (\"Best logistic regression test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 9 Try  with regularization (use C=1)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best regularized logistic regression training error: 0.000500\n",
      "Best regularized logistic regression test error: 0.255793\n"
     ]
    }
   ],
   "source": [
    "# ADD YOUR CODE\n",
    "\n",
    "lr = linear_model.LogisticRegression( random_state=0, C=1, max_iter=500 ).fit(X_train, y_train)\n",
    "training_error = 1- lr.score(X_train,y_train)\n",
    "test_error = 1 - lr.score(X_test, y_test)\n",
    "\n",
    "print (\"Best regularized logistic regression training error: %f\" % training_error)\n",
    "print (\"Best regularized logistic regression test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 3\n",
    "Compare and discuss:\n",
    "- the results from SVM with m=600 and with m=2000 training data points. If you stopped the SVM, include such aspect in your comparison.\n",
    "- the results of SVM and of Logistic Regression\n",
    "\n",
    "When I trained the SVM model with m=2000 training data points I observed better generalization performance of my model than I observed when I train my model with m= 600. SVM test error reduced to 0.11 which was on average between 0.3 - 0.4 range. Logistic Regression model test error was 0.28 before regularization and after the regularization the it reduced to 0.25. This may seem like a slight difference but training models with much more training samples or high number of data with the regularization, the models are tended to produce better training and test accuracies. Also training with more data is important from the perspective of generalization, when the model encountered with a out sample data which is a sample the model has not encountered before, the model will be able make better predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 10\n",
    "Plot an item of clothing that is missclassified by logistic regression and correctly classified by SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[500,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Prediction:  [3] true label:  4\n",
      "SVM Prediction:  [4] true label:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_index = 500\n",
    "\n",
    "X = X_test[sample_index,:].reshape(-1,1)\n",
    "X = X.reshape(1,784)\n",
    "LR_prediction = lr.predict(X)\n",
    "print('Logistic Regression Prediction: ', LR_prediction, 'true label: ', y_test[sample_index])\n",
    "\n",
    "SVM_prediction = best_SVM.predict(X)\n",
    "print('SVM Prediction: ', SVM_prediction, 'true label: ', y_test[sample_index])\n",
    "\n",
    "plt.imshow( X.reshape(28,28), cmap = plt.cm.gray_r, interpolation = \"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 11\n",
    "Plot the confusion matrix for the SVM classifier and for logistic regression.\n",
    "The confusion matrix has one column for each predicted label and one row for each true label. \n",
    "It shows for each class in the corresponding row how many samples belonging to that class gets each possible output label.\n",
    "Notice that the diagonal contains the correctly classified samples, while the other cells correspond to errors.\n",
    "You can obtain it with the sklearn.metrics.confusion_matrix function (see the documentation).\n",
    "Try also to normalize the confusion matrix by the number of samples in each class in order to measure the accuracy on each single class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and frequencies in test set:  [5822 5777 5812 5808 5798 5802 5793 5793 5796 5799]\n",
      "\n",
      " Confusion matrix SVM  \n",
      " \n",
      " [[5314    8    8   27  139   69    8   78  131   40]\n",
      " [  17 5081  137   50  119   14  128    3   89  139]\n",
      " [   0  104 4689  131   64   28  450   18  233   95]\n",
      " [  10  115  124 5264   55   60   16   21  133   10]\n",
      " [ 118  131  116   36 5059   15   78   40   98  107]\n",
      " [  41   75  153  179   31 5154   58   12   84   15]\n",
      " [   9  156  306   32  175   16 4986   33   48   32]\n",
      " [  63   14   56   48  180   33  106 5187   68   38]\n",
      " [  18  134  108   51   17   55  137    3 5251   22]\n",
      " [  14  153  178   30   88   15   17   11   58 5235]]\n",
      "\n",
      " Confusion matrix SVM (normalized)   \n",
      " \n",
      " [[0.91 0.00 0.00 0.00 0.02 0.01 0.00 0.01 0.02 0.01]\n",
      " [0.00 0.88 0.02 0.01 0.02 0.00 0.02 0.00 0.02 0.02]\n",
      " [0.00 0.02 0.81 0.02 0.01 0.00 0.08 0.00 0.04 0.02]\n",
      " [0.00 0.02 0.02 0.91 0.01 0.01 0.00 0.00 0.02 0.00]\n",
      " [0.02 0.02 0.02 0.01 0.87 0.00 0.01 0.01 0.02 0.02]\n",
      " [0.01 0.01 0.03 0.03 0.01 0.89 0.01 0.00 0.01 0.00]\n",
      " [0.00 0.03 0.05 0.01 0.03 0.00 0.86 0.01 0.01 0.01]\n",
      " [0.01 0.00 0.01 0.01 0.03 0.01 0.02 0.90 0.01 0.01]\n",
      " [0.00 0.02 0.02 0.01 0.00 0.01 0.02 0.00 0.91 0.00]\n",
      " [0.00 0.03 0.03 0.01 0.02 0.00 0.00 0.00 0.01 0.90]]\n",
      "\n",
      " Confusion matrix LR  \n",
      " \n",
      " [[4819   24   25   32  293  200   11  156   87  175]\n",
      " [  16 4163  488   53  250   76  211   32  191  297]\n",
      " [   6  333 3449   99  188  182  744   85  424  302]\n",
      " [  23  137  139 4345  205  422   64   93  301   79]\n",
      " [ 177  205  264   85 4189   87  120  120  173  378]\n",
      " [  87  128  287  283   73 4615  106   55  108   60]\n",
      " [  40  324  533   42  251   85 4215   69  138   96]\n",
      " [ 151   43   97  134  195  133  172 4623  133  112]\n",
      " [  30  348  363   99  100  170  240   13 4347   86]\n",
      " [  60  265  340   47  267   46   80   77  218 4399]]\n",
      "\n",
      " Confusion matrix LR (normalized)   \n",
      " \n",
      " [[0.83 0.00 0.00 0.01 0.05 0.03 0.00 0.03 0.01 0.03]\n",
      " [0.00 0.72 0.08 0.01 0.04 0.01 0.04 0.01 0.03 0.05]\n",
      " [0.00 0.06 0.59 0.02 0.03 0.03 0.13 0.01 0.07 0.05]\n",
      " [0.00 0.02 0.02 0.75 0.04 0.07 0.01 0.02 0.05 0.01]\n",
      " [0.03 0.04 0.05 0.01 0.72 0.02 0.02 0.02 0.03 0.07]\n",
      " [0.01 0.02 0.05 0.05 0.01 0.80 0.02 0.01 0.02 0.01]\n",
      " [0.01 0.06 0.09 0.01 0.04 0.01 0.73 0.01 0.02 0.02]\n",
      " [0.03 0.01 0.02 0.02 0.03 0.02 0.03 0.80 0.02 0.02]\n",
      " [0.01 0.06 0.06 0.02 0.02 0.03 0.04 0.00 0.75 0.01]\n",
      " [0.01 0.05 0.06 0.01 0.05 0.01 0.01 0.01 0.04 0.76]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "np.set_printoptions(precision=2, suppress=True, floatmode='fixed') # for better aligned printing of confusion matrix use floatmode='fixed'\n",
    "\n",
    "u, counts = np.unique(y_test, return_counts=True)\n",
    "print(\"Labels and frequencies in test set: \", counts)\n",
    "\n",
    "y_pred_svm = best_SVM.predict(X_test)\n",
    "confusion_SVM = confusion_matrix(y_test,y_pred_svm)\n",
    "print(\"\\n Confusion matrix SVM  \\n \\n\", confusion_SVM)\n",
    "print(\"\\n Confusion matrix SVM (normalized)   \\n \\n\", confusion_SVM /counts[:,None] )\n",
    "\n",
    "y_pred_lr =  lr.predict(X_test)\n",
    "confusion_LR = confusion_matrix(y_test,y_pred_lr)\n",
    "print(\"\\n Confusion matrix LR  \\n \\n\", confusion_LR)\n",
    "print(\"\\n Confusion matrix LR (normalized)   \\n \\n\", confusion_LR /counts[:,None] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion matrix SVM  \n",
      " \n",
      " [[0.09 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.09 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.08 0.00 0.00 0.00 0.01 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.09 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.09 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.09 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.01 0.00 0.00 0.00 0.09 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.09 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.09 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.09]]\n",
      "\n",
      " Confusion matrix LR  \n",
      " \n",
      " [[0.08 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.07 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.01]\n",
      " [0.00 0.01 0.06 0.00 0.00 0.00 0.01 0.00 0.01 0.01]\n",
      " [0.00 0.00 0.00 0.07 0.00 0.01 0.00 0.00 0.01 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.07 0.00 0.00 0.00 0.00 0.01]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.08 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.01 0.01 0.00 0.00 0.00 0.07 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.08 0.00 0.00]\n",
      " [0.00 0.01 0.01 0.00 0.00 0.00 0.00 0.00 0.07 0.00]\n",
      " [0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.08]]\n"
     ]
    }
   ],
   "source": [
    "# ADD CODE TO NORMALIZE CONFUSION MATRIX AND PRINT THE NORMALIZED MATRIX\n",
    "y_pred_svm = best_SVM.predict(X_test)\n",
    "confusion_SVM = confusion_matrix(y_test,y_pred_svm, normalize='all')\n",
    "print(\"\\n Confusion matrix SVM  \\n \\n\", confusion_SVM)\n",
    "\n",
    "\n",
    "y_pred_lr =  lr.predict(X_test)\n",
    "confusion_LR = confusion_matrix(y_test,y_pred_lr, normalize = 'all')\n",
    "print(\"\\n Confusion matrix LR  \\n \\n\", confusion_LR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 4\n",
    "Have a look at the confusion matrices and comment on the obtained accuracies. Why some classes have lower accuracies and others an higher one ? Make some guesses on the possible causes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtained higher accuracies demonstrate that the model is good at classifying this classes. If the model has classified great number of test data as correct than the accuracy will be high in the confusion matrix for this class. But this is correct only in the diagonal. Because diagonal matches consist of exact matches like prediction is 1, and the correctl label is 1, or prediction is 2 and the correct label is 2, and so on. Therefore if diagonal consist of high values this is a good sign for the model performance in terms of classification predictions. On the other hand, the cells other than the diagonals should have low values so that the wrong predictions would be less. Other cells introduce the performance of the different class matches, for instance, prediction is 1, and the correct label is 2. The cell in this match introduce the how many confusions or wrong predictions that the model have made. Observing the confusion matrix we can make significant extractions in order to find at which points is our model in confusion, and from there we can take some measures, for instance adding some more samples belong to this class. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
